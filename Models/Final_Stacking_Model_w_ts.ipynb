{
 "cells": [
  {
   "cell_type": "code",
   "id": "939bfb8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "939bfb8a",
    "outputId": "f57b0558-c66e-4418-f2dd-3f154c2a8aab",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:05.198871Z",
     "start_time": "2026-02-06T18:14:02.949242400Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, accuracy_score, classification_report, r2_score as r2\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "import keras\n",
    "from keras.constraints import max_norm as MaxNorm\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (11.0, 8.0)\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a95cd3b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "a95cd3b8",
    "outputId": "04c2636b-fbb1-4eb2-8f61-b596147f865e",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:05.404156800Z",
     "start_time": "2026-02-06T18:14:05.198871Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv('../Data/address_data_combined_ts.csv')\n",
    "\n",
    "# 2. FIX: Removed 'Unnamed: 0' because it doesn't exist in your file\n",
    "X = df.drop(columns=['Address', 'FLAG'])\n",
    "y = df['FLAG']\n",
    "\n",
    "# 3. Split Data\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# List of columns to log-transform\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "       'Time Diff between first and last (Mins)',\n",
    "       'Unique Received From Addresses', 'min value received',\n",
    "       'max value received ', 'avg val received', 'min val sent',\n",
    "       'avg val sent', 'total transactions (including tnx to create contract',\n",
    "       'total ether received', 'total ether balance','adjusted_eth_value__absolute_sum_of_changes',\n",
    "     'adjusted_eth_value__mean_abs_change',\n",
    "     'adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0',\n",
    "     'adjusted_eth_value__sum_values',\n",
    "     'adjusted_eth_value__abs_energy',\n",
    "     'adjusted_eth_value__ratio_value_number_to_time_series_length',\n",
    "     'adjusted_eth_value__quantile__q_0.1',\n",
    "     'adjusted_eth_value__count_below__t_0',\n",
    "     'adjusted_eth_value__count_above__t_0',\n",
    "     'adjusted_eth_value__median']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 4. Log Transformation\n",
    "# Note: This loop is fine, but ensures we don't log(0) which is undefined.\n",
    "for c in columns:\n",
    "    # Check if column exists first to avoid crashing\n",
    "    if c in X_train_full.columns:\n",
    "        X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "        X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# 5. Scaling\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 6. FIX: Check for NaNs effectively\n",
    "# np.isnan() alone returns a huge True/False grid. .sum() counts the errors.\n",
    "print(\"Total Missing Values (NaN) in Train:\", np.isnan(X_train_full).sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing Values (NaN) in Train: 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "tV_SwUsUwSxo",
   "metadata": {
    "id": "tV_SwUsUwSxo",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:05.419996400Z",
     "start_time": "2026-02-06T18:14:05.404156800Z"
    }
   },
   "source": [
    "X_train_Xgb, X_test_Xgb, y_train_Xgb, y_Xgb = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "2c286bb2",
   "metadata": {
    "id": "2c286bb2",
    "outputId": "2bcbf176-efb5-40e9-bc09-050732fb082e",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:05.448052800Z",
     "start_time": "2026-02-06T18:14:05.419996400Z"
    }
   },
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(X_train_full.shape)\n",
    "X_train_full.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9744, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       Avg min between sent tnx  Avg min between received tnx  \\\n",
       "906                        0.00                           0.0   \n",
       "13918                      0.00                           0.0   \n",
       "5687                     159.65                           0.5   \n",
       "914                        0.00                           0.0   \n",
       "7100                       0.00                           0.0   \n",
       "\n",
       "       Time Diff between first and last (Mins)  \\\n",
       "906                                       0.00   \n",
       "13918                                     0.00   \n",
       "5687                                    320.30   \n",
       "914                                       0.00   \n",
       "7100                                    364.87   \n",
       "\n",
       "       Unique Received From Addresses  min value received  \\\n",
       "906                                 0            0.000000   \n",
       "13918                               1            0.500000   \n",
       "5687                                2            8.664005   \n",
       "914                                 0            0.000000   \n",
       "7100                                1            0.259262   \n",
       "\n",
       "       max value received   avg val received  min val sent  avg val sent  \\\n",
       "906               0.000000          0.000000      0.000000      0.000000   \n",
       "13918             0.500000          0.500000      0.000000      0.000000   \n",
       "5687             92.335995         50.500000      7.000000     50.499508   \n",
       "914               0.000000          0.000000      0.000000      0.000000   \n",
       "7100              0.259262          0.259262      0.258642      0.258642   \n",
       "\n",
       "       total transactions (including tnx to create contract  ...  \\\n",
       "906                                                    0     ...   \n",
       "13918                                                  1     ...   \n",
       "5687                                                   4     ...   \n",
       "914                                                    0     ...   \n",
       "7100                                                   2     ...   \n",
       "\n",
       "       adjusted_eth_value__absolute_sum_of_changes  \\\n",
       "906                                       0.000000   \n",
       "13918                                     0.999861   \n",
       "5687                                    186.335011   \n",
       "914                                       0.000000   \n",
       "7100                                      0.517904   \n",
       "\n",
       "       adjusted_eth_value__mean_abs_change  \\\n",
       "906                               0.000000   \n",
       "13918                             0.999861   \n",
       "5687                             62.111670   \n",
       "914                               0.000000   \n",
       "7100                              0.517904   \n",
       "\n",
       "       adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0  \\\n",
       "906                                             0.000000                              \n",
       "13918                                           0.500139                              \n",
       "5687                                            0.487592                              \n",
       "914                                             0.000000                              \n",
       "7100                                            0.501197                              \n",
       "\n",
       "       adjusted_eth_value__sum_values  adjusted_eth_value__abs_energy  \\\n",
       "906                          0.000000                        0.000000   \n",
       "13918                        0.000139                        0.499861   \n",
       "5687                         0.000984                    17485.815895   \n",
       "914                          0.000000                        0.000000   \n",
       "7100                         0.000620                        0.134113   \n",
       "\n",
       "       adjusted_eth_value__ratio_value_number_to_time_series_length  \\\n",
       "906                                                  0.0              \n",
       "13918                                                1.0              \n",
       "5687                                                 1.0              \n",
       "914                                                  0.0              \n",
       "7100                                                 1.0              \n",
       "\n",
       "       adjusted_eth_value__quantile__q_0.1  \\\n",
       "906                               0.000000   \n",
       "13918                            -0.399875   \n",
       "5687                            -67.899311   \n",
       "914                               0.000000   \n",
       "7100                             -0.206852   \n",
       "\n",
       "       adjusted_eth_value__count_below__t_0  \\\n",
       "906                                     0.0   \n",
       "13918                                   0.5   \n",
       "5687                                    0.5   \n",
       "914                                     0.0   \n",
       "7100                                    0.5   \n",
       "\n",
       "       adjusted_eth_value__count_above__t_0  adjusted_eth_value__median  \n",
       "906                                     0.0                    0.000000  \n",
       "13918                                   0.5                    0.000070  \n",
       "5687                                    0.5                    0.832003  \n",
       "914                                     0.0                    0.000000  \n",
       "7100                                    0.5                    0.000310  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg min between sent tnx</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>min value received</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>min val sent</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>...</th>\n",
       "      <th>adjusted_eth_value__absolute_sum_of_changes</th>\n",
       "      <th>adjusted_eth_value__mean_abs_change</th>\n",
       "      <th>adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0</th>\n",
       "      <th>adjusted_eth_value__sum_values</th>\n",
       "      <th>adjusted_eth_value__abs_energy</th>\n",
       "      <th>adjusted_eth_value__ratio_value_number_to_time_series_length</th>\n",
       "      <th>adjusted_eth_value__quantile__q_0.1</th>\n",
       "      <th>adjusted_eth_value__count_below__t_0</th>\n",
       "      <th>adjusted_eth_value__count_above__t_0</th>\n",
       "      <th>adjusted_eth_value__median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.500139</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.499861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.399875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>159.65</td>\n",
       "      <td>0.5</td>\n",
       "      <td>320.30</td>\n",
       "      <td>2</td>\n",
       "      <td>8.664005</td>\n",
       "      <td>92.335995</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>186.335011</td>\n",
       "      <td>62.111670</td>\n",
       "      <td>0.487592</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>17485.815895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-67.899311</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.832003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259262</td>\n",
       "      <td>0.259262</td>\n",
       "      <td>0.259262</td>\n",
       "      <td>0.258642</td>\n",
       "      <td>0.258642</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517904</td>\n",
       "      <td>0.517904</td>\n",
       "      <td>0.501197</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.134113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.206852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "8d93a698",
   "metadata": {
    "id": "8d93a698",
    "outputId": "b5979466-0264-4637-fa49-065b10b22278",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:05.658482400Z",
     "start_time": "2026-02-06T18:14:05.481200500Z"
    }
   },
   "source": [
    "# Feature Engineering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "       'Time Diff between first and last (Mins)',\n",
    "       'Unique Received From Addresses', 'min value received',\n",
    "       'max value received ', 'avg val received', 'min val sent',\n",
    "       'avg val sent', 'total transactions (including tnx to create contract',\n",
    "       'total ether received', 'total ether balance','adjusted_eth_value__absolute_sum_of_changes',\n",
    "     'adjusted_eth_value__mean_abs_change',\n",
    "     'adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0',\n",
    "     'adjusted_eth_value__sum_values',\n",
    "     'adjusted_eth_value__abs_energy',\n",
    "     'adjusted_eth_value__ratio_value_number_to_time_series_length',\n",
    "     'adjusted_eth_value__quantile__q_0.1',\n",
    "     'adjusted_eth_value__count_below__t_0',\n",
    "     'adjusted_eth_value__count_above__t_0',\n",
    "     'adjusted_eth_value__median']\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Log for Skewed Data\n",
    "# log on both train and test data\n",
    "for c in columns:\n",
    "    X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "    X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Scaling\n",
    "# only use training data to fit, to avoid data leakage\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.isnan(X_train_full)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]], shape=(9744, 22))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "3bb509ec",
   "metadata": {
    "id": "3bb509ec",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:05.867745100Z",
     "start_time": "2026-02-06T18:14:05.834819300Z"
    }
   },
   "source": [
    "# --- IMPORTS ---\n",
    "from catboost import CatBoostClassifier\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import max_norm as MaxNorm\n",
    "\n",
    "# --- OPTIMAL PARAMETERS ---\n",
    "tabnet_params = {'gamma': 1.0,\n",
    "                 'lambda_sparse': 0,\n",
    "                 'momentum': 0.4,\n",
    "                 'n_steps': 8,\n",
    "                 'optimizer_params': {'lr': 0.025},\n",
    "                 'verbose': 0}\n",
    "\n",
    "xgb_params = {'learning_rate': 0.05,\n",
    "              'max_depth': 8,\n",
    "              'n_estimators': 1000}\n",
    "\n",
    "# Note: Ensure X_train_full is defined before running this\n",
    "mlp_params = {'input_dim': X_train_full.shape[1],\n",
    "              'H': 60,\n",
    "              'activation': 'relu',\n",
    "              'dropout_probability': 0.2,\n",
    "              'num_epochs': 75,\n",
    "              'num_layers': 10}\n",
    "\n",
    "svm_params = {'C': 1000,\n",
    "              'gamma': 1}\n",
    "\n",
    "rf_params = {'max_depth': 20,\n",
    "               'min_samples_leaf': 5,\n",
    "               'n_jobs': -1}\n",
    "\n",
    "lightgbm_params = {\"bagging_fraction\": 0.95,\n",
    "                   \"bagging_freq\": 1,\n",
    "                   \"feature_fraction\": 0.95,\n",
    "                   \"learning_rate\": 0.2,\n",
    "                   \"max_bin\": 300,\n",
    "                   \"max_depth\": 6,\n",
    "                   \"min_gain_to_split\": 0,\n",
    "                   \"num_leaves\": 20}\n",
    "\n",
    "# --- NEW: CATBOOST PARAMETERS ---\n",
    "catboost_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'eval_metric': 'AUC',\n",
    "    'verbose': 0,  # Silent training\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "def compile_mlp(input_dim, H, num_epochs, num_layers, activation, dropout_probability):\n",
    "    # Creating Sequential MLP\n",
    "    model_n = Sequential()\n",
    "    model_n.add(layers.Dense(H, input_shape=(input_dim, ), activation= activation))\n",
    "\n",
    "    for _ in range(num_layers - 1):\n",
    "        model_n.add(layers.Dense(H, activation= activation, kernel_constraint=MaxNorm(3)))\n",
    "        model_n.add(layers.Dropout(dropout_probability))\n",
    "\n",
    "    model_n.add(layers.Dense(1, activation='sigmoid'))\n",
    "    # configure the model\n",
    "    model_n.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC(from_logits=True)])\n",
    "    return model_n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9c034817",
   "metadata": {
    "id": "9c034817",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:06.006121600Z",
     "start_time": "2026-02-06T18:14:05.977556300Z"
    }
   },
   "source": [
    "# get a list of models to evaluate\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier  # <--- 1. Import Added\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    mlp = KerasClassifier(model = compile_mlp, **mlp_params)\n",
    "    tabnet = TabNetClassifier(**tabnet_params)\n",
    "\n",
    "    models['tabnet'] = tabnet\n",
    "    models['svm'] = svm.SVC(**svm_params)\n",
    "    models['xgboost'] = XGBClassifier(**xgb_params)\n",
    "    models['mlp'] = mlp\n",
    "    models['lightGBM'] = lgb.LGBMClassifier(**lightgbm_params)\n",
    "    models['randomforest'] = RandomForestClassifier(**rf_params)\n",
    "\n",
    "    # --- 2. CatBoost Added Here ---\n",
    "    # Ensure catboost_params is defined before running this function\n",
    "    models['catboost'] = CatBoostClassifier(**catboost_params)\n",
    "    # ------------------------------\n",
    "\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)#, error_score='raise')\n",
    "    return scores"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "805bf398",
   "metadata": {
    "id": "805bf398",
    "outputId": "67f540a3-0859-4e0b-88ef-0905f9cbe1db",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:14:58.976079100Z",
     "start_time": "2026-02-06T18:14:06.006121600Z"
    }
   },
   "source": [
    "# define dataset\n",
    "X, y = X_train_full, y_train_full\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    if name == 'xgboost':\n",
    "        scores = evaluate_model(model, X_train_Xgb, y_train_Xgb)\n",
    "    else:\n",
    "        scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">tabnet 0.899 (0.008)\n",
      ">svm 0.918 (0.004)\n",
      ">xgboost 0.929 (0.006)\n",
      ">mlp 0.811 (0.055)\n",
      ">lightGBM 0.928 (0.006)\n",
      ">randomforest 0.911 (0.006)\n",
      ">catboost 0.931 (0.007)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1100x800 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b017856f",
   "metadata": {
    "id": "b017856f",
    "outputId": "12322ef9-efc2-49ab-d6cd-b84e8d4e160f",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:17:51.954395900Z",
     "start_time": "2026-02-06T18:14:58.999031600Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "# Creating Stacking model - Initialized using logistic regression model\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    # This automatically picks up CatBoost because we updated get_models() earlier\n",
    "    for key, value in get_models().items():\n",
    "        try:\n",
    "            value._estimator_type = 'classifier'\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        finally:\n",
    "            level0.append([key, value])\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "    return model\n",
    "\n",
    "# Pipeline to get all models\n",
    "def get_models2():\n",
    "    models = dict()\n",
    "    models['tabnet'] = TabNetClassifier(**tabnet_params)\n",
    "    models['svm'] = svm.SVC(**svm_params)\n",
    "    models['xgboost'] = XGBClassifier(**xgb_params)\n",
    "    models['mlp'] = KerasClassifier(model=compile_mlp, **mlp_params)\n",
    "\n",
    "    # Updated to use your optimal params\n",
    "    models['lightGBM'] = lgb.LGBMClassifier(**lightgbm_params)\n",
    "\n",
    "    # --- NEW: ADD CATBOOST HERE ---\n",
    "    # This ensures it shows up in your final comparison table\n",
    "    models['catboost'] = CatBoostClassifier(**catboost_params)\n",
    "    # ------------------------------\n",
    "\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "# Getting predictions from all models to evaluate performance on test set\n",
    "predictions, names2, timing_list = list(), list(), list()\n",
    "\n",
    "print(\"Starting final training loop...\")\n",
    "\n",
    "for name, model in get_models2().items():\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Special handling for XGBoost if it uses specific split\n",
    "    if name == 'xgboost':\n",
    "        model.fit(X_train_Xgb, y_train_Xgb)\n",
    "        predictions.append(model.predict(X_test_Xgb))\n",
    "    else:\n",
    "        # CatBoost and others fall here (Using standard X, y)\n",
    "        model.fit(X, y)\n",
    "        predictions.append(model.predict(X_test))\n",
    "\n",
    "    names2.append(name)\n",
    "    final_time = time.time()\n",
    "    timing_list.append(final_time - current_time)\n",
    "    print(f\"âœ… Finished training {name}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting final training loop...\n",
      "âœ… Finished training tabnet\n",
      "âœ… Finished training svm\n",
      "âœ… Finished training xgboost\n",
      "\u001B[1m305/305\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 922us/step - auc: 0.7773 - loss: 0.5574\n",
      "\u001B[1m131/131\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step\n",
      "âœ… Finished training mlp\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 4398, number of negative: 5346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6585\n",
      "[LightGBM] [Info] Number of data points in the train set: 9744, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.451355 -> initscore=-0.195199\n",
      "[LightGBM] [Info] Start training from score -0.195199\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "âœ… Finished training lightGBM\n",
      "âœ… Finished training catboost\n",
      "\u001B[1m131/131\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "âœ… Finished training stacking\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e090999a",
   "metadata": {
    "id": "e090999a",
    "outputId": "9571ae11-d111-4f5f-f2b8-a745b06f5b88",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:17:52.053111700Z",
     "start_time": "2026-02-06T18:17:51.994292700Z"
    }
   },
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, accuracy_score, precision_score\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df['Model'] = names2\n",
    "results_df['Time taken'] = timing_list\n",
    "\n",
    "# --- UPDATE: Added catboost_params to match the 7 models ---\n",
    "results_df['Optimal Parameters'] = [\n",
    "    tabnet_params,\n",
    "    svm_params,\n",
    "    xgb_params,\n",
    "    mlp_params,\n",
    "    lightgbm_params,\n",
    "    catboost_params,   # <--- ADDED THIS (Model #6)\n",
    "    None               # Stacking (Model #7)\n",
    "]\n",
    "\n",
    "metrics_dict = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'F1': f1_score,\n",
    "    'ROC-AUC': roc_auc_score\n",
    "}\n",
    "\n",
    "for metric, func in metrics_dict.items():\n",
    "    storage = []\n",
    "    for prediction in predictions:\n",
    "        storage.append(func(y_test, prediction))\n",
    "    results_df[metric] = storage\n",
    "\n",
    "# Display the final leaderboard\n",
    "results_df.sort_values(['Accuracy', 'ROC-AUC'], ascending=[False, False])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Model  Time taken                                 Optimal Parameters  \\\n",
       "5  catboost    2.497879  {'iterations': 1000, 'learning_rate': 0.05, 'd...   \n",
       "6  stacking  126.420559                                               None   \n",
       "2   xgboost    0.958134  {'learning_rate': 0.05, 'max_depth': 8, 'n_est...   \n",
       "4  lightGBM    1.248110  {'bagging_fraction': 0.95, 'bagging_freq': 1, ...   \n",
       "1       svm    3.123794                            {'C': 1000, 'gamma': 1}   \n",
       "0    tabnet   36.920127  {'gamma': 1.0, 'lambda_sparse': 0, 'momentum':...   \n",
       "3       mlp    1.774095  {'input_dim': 22, 'H': 60, 'activation': 'relu...   \n",
       "\n",
       "   Accuracy  Precision    Recall        F1   ROC-AUC  \n",
       "5  0.941092   0.935673  0.933687  0.934679  0.940436  \n",
       "6  0.940852   0.934713  0.934218  0.934465  0.940265  \n",
       "2  0.940134   0.934148  0.933156  0.933652  0.939516  \n",
       "4  0.933429   0.924907  0.927851  0.926377  0.932935  \n",
       "1  0.928400   0.919577  0.922016  0.920795  0.927835  \n",
       "0  0.916667   0.911182  0.903448  0.907299  0.915495  \n",
       "3  0.873324   0.875415  0.838727  0.856678  0.870258  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time taken</th>\n",
       "      <th>Optimal Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>catboost</td>\n",
       "      <td>2.497879</td>\n",
       "      <td>{'iterations': 1000, 'learning_rate': 0.05, 'd...</td>\n",
       "      <td>0.941092</td>\n",
       "      <td>0.935673</td>\n",
       "      <td>0.933687</td>\n",
       "      <td>0.934679</td>\n",
       "      <td>0.940436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stacking</td>\n",
       "      <td>126.420559</td>\n",
       "      <td>None</td>\n",
       "      <td>0.940852</td>\n",
       "      <td>0.934713</td>\n",
       "      <td>0.934218</td>\n",
       "      <td>0.934465</td>\n",
       "      <td>0.940265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.958134</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
       "      <td>0.940134</td>\n",
       "      <td>0.934148</td>\n",
       "      <td>0.933156</td>\n",
       "      <td>0.933652</td>\n",
       "      <td>0.939516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightGBM</td>\n",
       "      <td>1.248110</td>\n",
       "      <td>{'bagging_fraction': 0.95, 'bagging_freq': 1, ...</td>\n",
       "      <td>0.933429</td>\n",
       "      <td>0.924907</td>\n",
       "      <td>0.927851</td>\n",
       "      <td>0.926377</td>\n",
       "      <td>0.932935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>3.123794</td>\n",
       "      <td>{'C': 1000, 'gamma': 1}</td>\n",
       "      <td>0.928400</td>\n",
       "      <td>0.919577</td>\n",
       "      <td>0.922016</td>\n",
       "      <td>0.920795</td>\n",
       "      <td>0.927835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tabnet</td>\n",
       "      <td>36.920127</td>\n",
       "      <td>{'gamma': 1.0, 'lambda_sparse': 0, 'momentum':...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.911182</td>\n",
       "      <td>0.903448</td>\n",
       "      <td>0.907299</td>\n",
       "      <td>0.915495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1.774095</td>\n",
       "      <td>{'input_dim': 22, 'H': 60, 'activation': 'relu...</td>\n",
       "      <td>0.873324</td>\n",
       "      <td>0.875415</td>\n",
       "      <td>0.838727</td>\n",
       "      <td>0.856678</td>\n",
       "      <td>0.870258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "8ec68df3",
   "metadata": {
    "id": "8ec68df3",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2026-02-06T18:17:52.208095400Z",
     "start_time": "2026-02-06T18:17:52.090343900Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# savingthe  model xgboost",
   "id": "3e01a44382f3dc69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T18:17:53.197652100Z",
     "start_time": "2026-02-06T18:17:52.277203300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"--- 1. Loading and Preparing Data ---\")\n",
    "\n",
    "# 1. Load Data (Make sure the path is correct for your computer)\n",
    "df = pd.read_csv('../Data/address_data_combined_ts.csv')\n",
    "\n",
    "# 2. Drop columns we don't need\n",
    "# Note: We removed 'Unnamed: 0' since your file doesn't have it\n",
    "X = df.drop(columns=['Address', 'FLAG'])\n",
    "y = df['FLAG']\n",
    "\n",
    "# 3. Split the data (This creates the missing 'X_train_full' variable)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Log Transformation (Math stuff to make data better for AI)\n",
    "columns_to_log = [\n",
    "    'Avg min between sent tnx', 'Avg min between received tnx',\n",
    "    'Time Diff between first and last (Mins)', 'Unique Received From Addresses',\n",
    "    'min value received', 'max value received ', 'avg val received',\n",
    "    'min val sent', 'avg val sent',\n",
    "    'total transactions (including tnx to create contract',\n",
    "    'total ether received', 'total ether balance',\n",
    "    'adjusted_eth_value__absolute_sum_of_changes',\n",
    "    'adjusted_eth_value__mean_abs_change',\n",
    "    'adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0',\n",
    "    'adjusted_eth_value__sum_values', 'adjusted_eth_value__abs_energy',\n",
    "    'adjusted_eth_value__ratio_value_number_to_time_series_length',\n",
    "    'adjusted_eth_value__quantile__q_0.1', 'adjusted_eth_value__count_below__t_0',\n",
    "    'adjusted_eth_value__count_above__t_0', 'adjusted_eth_value__median'\n",
    "]\n",
    "\n",
    "# Apply log safely\n",
    "for c in columns_to_log:\n",
    "    if c in X_train_full.columns:\n",
    "        X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# 5. Scaling (The Translator)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "\n",
    "print(\"--- 2. Training the Model ---\")\n",
    "\n",
    "# 6. Define the Winner Model (XGBoost)\n",
    "best_model = XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 7. Train it\n",
    "best_model.fit(X_train_full, y_train_full)\n",
    "print(\"Model Trained!\")\n",
    "\n",
    "print(\"--- 3. Saving Files ---\")\n",
    "\n",
    "# 8. Create 'models' folder if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "    print(\"Created new 'models' folder.\")\n",
    "\n",
    "# 9. Save both the Brain (Model) and the Translator (Scaler)\n",
    "joblib.dump(best_model, 'models/my_best_fraud_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "\n",
    "print(\"Success! Files saved in 'models/' folder.\")"
   ],
   "id": "d0e25dc18f96a2d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading and Preparing Data ---\n",
      "--- 2. Training the Model ---\n",
      "Model Trained!\n",
      "--- 3. Saving Files ---\n",
      "Success! Files saved in 'models/' folder.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T18:17:53.350125300Z",
     "start_time": "2026-02-06T18:17:53.316749800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- FRAUD HUNTER SCRIPT ---\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the data again\n",
    "df = pd.read_csv('../Data/address_data_combined_ts.csv')\n",
    "\n",
    "# 2. Filter: Find rows where FLAG is 1 (Confirmed Fraud)\n",
    "# We also want a \"Clear\" example, so let's pick one with high transaction count\n",
    "real_fraudsters = df[ (df['FLAG'] == 1) & (df['total transactions (including tnx to create contract'] > 10) ]\n",
    "\n",
    "# 3. Pick the first one found\n",
    "fraud_row = real_fraudsters.iloc[0]\n",
    "\n",
    "# 4. Print it as a Dictionary so you can copy-paste it\n",
    "print(\"fake_data = {\")\n",
    "for col in fraud_row.index:\n",
    "    if col not in ['Address', 'FLAG', 'Unnamed: 0']:\n",
    "        print(f\"    '{col}': [{fraud_row[col]}],\")\n",
    "print(\"}\")"
   ],
   "id": "104a1fa21f569e48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸš¨ COPY THIS DATA INTO YOUR TEST SCRIPT ---\n",
      "fake_data = {\n",
      "    'Avg min between sent tnx': [1179.02],\n",
      "    'Avg min between received tnx': [1124.89],\n",
      "    'Time Diff between first and last (Mins)': [25126.45],\n",
      "    'Unique Received From Addresses': [13],\n",
      "    'min value received': [0.0],\n",
      "    'max value received ': [0.75],\n",
      "    'avg val received': [0.176666667],\n",
      "    'min val sent': [0.145],\n",
      "    'avg val sent': [0.419269824],\n",
      "    'total transactions (including tnx to create contract': [22],\n",
      "    'total ether received': [2.65],\n",
      "    'total ether balance': [-0.28488877],\n",
      "    'adjusted_eth_value__absolute_sum_of_changes': [7.66977754],\n",
      "    'adjusted_eth_value__mean_abs_change': [0.3652275019047619],\n",
      "    'adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0': [0.0202370540854782],\n",
      "    'adjusted_eth_value__sum_values': [-0.2848887700000001],\n",
      "    'adjusted_eth_value__abs_energy': [3.335465711308085],\n",
      "    'adjusted_eth_value__ratio_value_number_to_time_series_length': [0.4090909090909091],\n",
      "    'adjusted_eth_value__quantile__q_0.1': [-0.267420588],\n",
      "    'adjusted_eth_value__count_below__t_0': [0.3636363636363636],\n",
      "    'adjusted_eth_value__count_above__t_0': [0.6818181818181818],\n",
      "    'adjusted_eth_value__median': [0.15],\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
